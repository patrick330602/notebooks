{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "arztKzk9fzjD"
   },
   "source": [
    "# Loading The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IWpG2kklZJy2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from numpy.random import seed\n",
    "\n",
    "# load the iris dataset\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "eMpQ9ZdlZj6W",
    "outputId": "0ab923c1-dc71-4bfe-fd4e-e6a329790ce8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target[:100] # the first 100 elements are either 0, or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vzmsU5jDZd3I"
   },
   "outputs": [],
   "source": [
    "#select the target data (first 100 data points) with slicing\n",
    "X_iris = iris.data[:100]\n",
    "y_iris = iris.target[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nRIgNjFyZ_5g"
   },
   "outputs": [],
   "source": [
    "# spliting the data into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_iris, y_iris, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iUJeOsMjaneF",
    "outputId": "e87053b2-8a3a-475b-bc6b-665c41b3c8e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 4), (20, 4), (80,), (20,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WflEz5xbgJKT"
   },
   "source": [
    "# Classification with a Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "edgE_Hanbl0Z"
   },
   "outputs": [],
   "source": [
    "# import the Perceptron library from sklearn and train the perceptron\n",
    "from sklearn.linear_model import Perceptron\n",
    "# import the accuracy_score from sklearn\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "6Ww8r5JsbrDC",
    "outputId": "a6bb7f30-f214-4bd0-ca2f-6c5f3526b537"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wotin\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=0.5,\n",
       "      fit_intercept=True, max_iter=None, n_iter=None, n_iter_no_change=5,\n",
       "      n_jobs=None, penalty=None, random_state=0, shuffle=True, tol=None,\n",
       "      validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define and train the perceptron\n",
    "clf = Perceptron(fit_intercept=True, eta0=0.5) # eta0 is the learning rate\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "U5omuwoMcosu",
    "outputId": "714ec9ad-df7f-4efd-a2bf-e1cdc669b6c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " y_pred_train = clf.predict(X_train)\n",
    "accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dfLJMAarcvX5",
    "outputId": "4b284f26-5182-48ba-d64f-684aed75db03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0h3Og2qolbUV"
   },
   "source": [
    "# Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GlJyl69GqDA9"
   },
   "outputs": [],
   "source": [
    "#First we implement cross-validation ourselves\n",
    "#Split the training set into training and validation sets. DO NOT USE THE TEST SET FOR CROSS-VALIDATION.\n",
    "#Here we perform hold-out validation using 80% of the data for training and 20% for validation\n",
    "\n",
    "X_train_new = X_train[:int(len(X_train)*0.8), :]\n",
    "y_train_new = y_train[:int(len(y_train)*0.8)]\n",
    "X_validation = X_train[int(len(X_train)*0.8):, :]\n",
    "y_validation = y_train[int(len(y_train)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DjBS_ZAwqWDl",
    "outputId": "04e94855-4562-488d-d343-3d6ebb99d496"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64, 4), (64,), (16, 4), (16,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_new.shape, y_train_new.shape, X_validation.shape, y_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "51UmrRiOlt0W",
    "outputId": "aa92285a-5a42-4d23-f919-7e30618143a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.34 -1.    1.6   0.6 ]]\n",
      "for eta = 0.2 accuracy: 1.0\n",
      "[[-1.36 -4.    6.4   2.4 ]]\n",
      "for eta = 0.8 accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wotin\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\wotin\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "eta_values = [0.2, 0.8]\n",
    "for eta in eta_values:\n",
    "  clf = Perceptron(fit_intercept=True, eta0=eta) # training the model on the training set\n",
    "  clf.fit(X_train_new, y_train_new)\n",
    "  y_pred_validation = clf.predict(X_validation) #evaluating the performance on validation set\n",
    "  print(clf.coef_)\n",
    "  print(\"for eta = \" +str(eta) + \" accuracy: \" + str(accuracy_score(y_validation, y_pred_validation)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "48nyuxoFq3UM"
   },
   "outputs": [],
   "source": [
    "#We can also use sklearn.model_selection to perform cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "hX4A3YzSleHr",
    "outputId": "3f6b9b89-9299-47ec-e03c-1fa397e615d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wotin\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\wotin\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\wotin\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\wotin\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\wotin\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\wotin\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\wotin\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\wotin\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\wotin\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\wotin\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\wotin\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "      fit_intercept=True, max_iter=None, n_iter=None, n_iter_no_change=5,\n",
       "      n_jobs=None, penalty=None, random_state=0, shuffle=True, tol=None,\n",
       "      validation_fraction=0.1, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'eta0': (0.8, 0.2)}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'eta0':(0.8, 0.2)}\n",
    "perceptron_model = Perceptron() \n",
    "clf = GridSearchCV(perceptron_model, parameters, cv=5, return_train_score=True) #cv=5 means 5-fold cross-validation \n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "6aWnLcHaofdB",
    "outputId": "1728604a-a4cb-424e-efe2-87573ee7f643"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00236073, 0.0062017 ]),\n",
       " 'std_fit_time': array([0.00472145, 0.00762548]),\n",
       " 'mean_score_time': array([0.00212016, 0.        ]),\n",
       " 'std_score_time': array([0.00424032, 0.        ]),\n",
       " 'param_eta0': masked_array(data=[0.8, 0.2],\n",
       "              mask=[False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'eta0': 0.8}, {'eta0': 0.2}],\n",
       " 'split0_test_score': array([1., 1.]),\n",
       " 'split1_test_score': array([1., 1.]),\n",
       " 'split2_test_score': array([1., 1.]),\n",
       " 'split3_test_score': array([1., 1.]),\n",
       " 'split4_test_score': array([1., 1.]),\n",
       " 'mean_test_score': array([1., 1.]),\n",
       " 'std_test_score': array([0., 0.]),\n",
       " 'rank_test_score': array([1, 1]),\n",
       " 'split0_train_score': array([1., 1.]),\n",
       " 'split1_train_score': array([1., 1.]),\n",
       " 'split2_train_score': array([1., 1.]),\n",
       " 'split3_train_score': array([1., 1.]),\n",
       " 'split4_train_score': array([1., 1.]),\n",
       " 'mean_train_score': array([1., 1.]),\n",
       " 'std_train_score': array([0., 0.])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RafUZpLiuqA5"
   },
   "source": [
    "# DIY: Build your own Preceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bAWC8FOeto-g"
   },
   "outputs": [],
   "source": [
    "class Perceptron2(object):\n",
    "  \"\"\"Perceptron classifier.\n",
    "  Parameters\n",
    "  ------------\n",
    "  eta: float\n",
    "  Learning rate (between 0.0 and 1.0)\n",
    "  n_iter: int\n",
    "  Number of epochs, i.e. number of iteration passes over the training dataset.\n",
    "  Attributes\n",
    "  ------------\n",
    "  w_: 1d-array\n",
    "  Weights after fitting.\n",
    "  errors_: list\n",
    "  Number of misclassifications in every epoch.\n",
    "  random_state : int\n",
    "  The seed of the pseudo random number generator.\n",
    "  \"\"\"\n",
    "  def __init__(self, eta=0.01, n_iter=100, random_state=1):\n",
    "    self.eta = eta\n",
    "    self.n_iter = n_iter\n",
    "    self.w_initialized = False\n",
    "    self.random_state = random_state\n",
    "    if random_state:\n",
    "      seed(random_state)\n",
    "    \n",
    "  def _initialize_weights(self, m):\n",
    "    \"\"\"Randomly initialize weights\"\"\"\n",
    "    self.w_ = np.random.normal(loc=0.0, scale=0.01, size=1 + m)\n",
    "    self.w_initialized = True\n",
    "\n",
    "  def net_input(self, X):\n",
    "    \"\"\"Calculate net input\"\"\"\n",
    "    return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "    \n",
    "  def predict(self, X):\n",
    "    \"\"\"Return class label after unit step for external usage.\"\"\"\n",
    "    return np.where(self.net_input(X) >= 0.0, 1, 0)\n",
    "  \n",
    "  def _update_weights(self, xi, target):\n",
    "    \"\"\"Apply Perceptron learning rule to update the weights for a single sample.\"\"\"\n",
    "    output = self.predict(xi)\n",
    "    self.w_[1:] += self.eta * xi * (target - output)\n",
    "    self.w_[0] += self.eta * (target - output)\n",
    "    \n",
    "  def fit(self, X, y):\n",
    "    \"\"\"Fit training data.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : {array-like}, shape = [n_samples, n_features]\n",
    "    Training vectors, where n_samples is the number of samples and\n",
    "    n_features is the number of features.\n",
    "    y : array-like, shape = [n_samples]\n",
    "    Target values.\n",
    "    Returns\n",
    "    -------\n",
    "    self : object\n",
    "    \"\"\"\n",
    "    # initialize the weight\n",
    "    self._initialize_weights(X.shape[1])\n",
    "    for _ in range(self.n_iter):\n",
    "      for xi, target in zip(X, y):\n",
    "        self._update_weights(xi, target)\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kmPUk0V4uYEZ",
    "outputId": "d6d91e25-8142-4482-b959-49ada8d487e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Perceptron2 at 0x2ce9b0428d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Perceptron2()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sZLE4akwuekb",
    "outputId": "b7a00446-fe8a-4199-f973-072281ae1a8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = clf.predict(X_train)\n",
    "accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-zO2zPkBuiJq",
    "outputId": "0a770154-39d7-412b-c087-66300197585a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-HrqN0jluku0",
    "outputId": "685972d4-3a76-4311-aa9c-0f292ff2e5ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00624345, -0.01011756, -0.04628172,  0.05927031,  0.03665408])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.w_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tutorial3_perceptron.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
